<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>机器学习基础（一）</title>
      <link href="/2019/12/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/2019/12/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>﻿# 机器学习基础（一）</p><h2 id="1-相关数学知识"><a href="#1-相关数学知识" class="headerlink" title="1 相关数学知识"></a>1 相关数学知识</h2><p>矩阵是线性代数中非常核心的内容，其优势是可以进行大规模的并行运算。</p><h3 id="1-1-标量"><a href="#1-1-标量" class="headerlink" title="1.1 标量"></a>1.1 标量</h3><p>标量其实就是应该独立存在的数。</p><h3 id="1-2-向量"><a href="#1-2-向量" class="headerlink" title="1.2 向量"></a>1.2 向量</h3><p>向量是按顺序排列的元素。</p><h3 id="1-3-矩阵"><a href="#1-3-矩阵" class="headerlink" title="1.3 矩阵"></a>1.3 矩阵</h3><p>矩阵是应该二维数组结构</p><h3 id="1-4-张量"><a href="#1-4-张量" class="headerlink" title="1.4 张量"></a>1.4 张量</h3><p>若数组的维度超过二维，那么我们就可以用张量来表示</p><h2 id="2-监督学习和无监督学习"><a href="#2-监督学习和无监督学习" class="headerlink" title="2 监督学习和无监督学习"></a>2 监督学习和无监督学习</h2><p>监督学习和无监督学习是在机器学习中经常提到的两个重要学习方法。</p><h3 id="2-1-监督学习"><a href="#2-1-监督学习" class="headerlink" title="2.1 监督学习"></a>2.1 监督学习</h3><p>提供一组输入数据和其对应的标签数据，然后搭建一个模型，让模型在泰国训练后准确的找到输入数据和标签数据之间的最优映射关系。在输入新的数据后，模型能够通过之前学到的最优映射关系，快速的预测初这组新数据的标签。</p><h4 id="2-1-1-回归问题"><a href="#2-1-1-回归问题" class="headerlink" title="2.1.1 回归问题"></a>2.1.1 回归问题</h4><p>回归问题就是使用监督学习的方法，让我们搭建的模型在训练后建立起来一个连续的线性映射关系，其重点如下：</p><ul><li>通过提供数据训练模型，是的模型得到映射关系并能够对新的输入数据进行预测。</li><li>我们得到的映射模型是线性连续的对应关系。<br><img alt="image" data-src="https://i.loli.net/2019/12/06/Q6sHRir8AkjVK2u.png" class="lazyload"><br>由图所示，其中x轴表示房屋的面积，y轴表示房屋的价格，用叉号表示的单点是房价和面积相对应的数据，途中的曲线就是我们使用单点数据通过监督学习的方法最终拟合出来的线性映射模型。<h4 id="2-1-2-分类问题"><a href="#2-1-2-分类问题" class="headerlink" title="2.1.2 分类问题"></a>2.1.2 分类问题</h4>分类问题就是让我们搭建的模型通过监督学习之后建立起来的一个离散的映射关系。<br><img alt="image" data-src="https://i.loli.net/2019/12/06/xHqYoB3zCSmFJE2.png" class="lazyload"><br>在图中使用的是两个维度的数据，x轴表示肿瘤尺寸的大小，y轴表示肿瘤的属性。因为y轴只输出两个离散的结果，即0和1，这里我们用0表示良性肿瘤，用1表示恶性肿瘤。<h3 id="2-2-无监督学习"><a href="#2-2-无监督学习" class="headerlink" title="2.2 无监督学习"></a>2.2 无监督学习</h3>无监督学习：提供一组墨鱼任何标签的输入数据，将其在我们搭建好的模型中进行训练，对整个训练过程不做任何的干涉，最后得到一个能够发现数据之间隐藏特征的映射模型，使用这个映射模型能够实现对新的输入数据的分类。<br><img alt="image" data-src="https://i.loli.net/2019/12/06/NtrAL5H2gZsuYjK.png" class="lazyload"><h2 id="3-欠拟合和过拟合"><a href="#3-欠拟合和过拟合" class="headerlink" title="3 欠拟合和过拟合"></a>3 欠拟合和过拟合</h2>我们可以将搭建的模型是否发生过拟合和欠拟合作为评价模型拟合程度好坏的标准。欠拟合的模型对已有数据的匹配性很差，但是对数据的噪声不是很敏感；过拟合的模型对已有数据的匹配性太好，但是对数据的噪声非常敏感。<h3 id="3-1-欠拟合"><a href="#3-1-欠拟合" class="headerlink" title="3.1 欠拟合"></a>3.1 欠拟合</h3>如下图所示，图a是已有房屋大小和价格的关系数据；图b是一个欠拟合模型，该模型虽然可以反映数据的一些特征，但是不能很好的对新数据进行准确的预测；欠拟合模型的缺点也非常明显，一旦新的输入数据房屋真实价格在模型中上下抖动，那么相同大小房屋的预测价格会与真实价格存在较大的误差。<br><img alt="image" data-src="https://i.loli.net/2019/12/06/hzp1d6vuxXEQy7W.png" class="lazyload"><br>若模型存在欠拟合问题，应用下述方法进行解决：</li><li>增加特征项：在大多数情况下，出现过拟合是因为我们不能准确把握数据的主要特征，所以我们可以尝试在模型中加入更多的和原数据有重要相关性的特征来训练搭建的模型，这样得到的模型可能会有更好的泛化能力。</li><li>构造复杂的多项式：这种方法很容易理解，我们知道一次项函数就是一条直线，二次项函数是一条抛物线，一次项和二次项函数的特性决定了它们的泛化能力是有局限性的，如果数据不在直线或者抛物线附近，那么必然出现欠拟合的情形，所以我们可以通过增加函数中的次项来增强模型的变化能力，从而提升其泛化能力。</li><li>减少正则化参数：正则化参数出现的目的其实是防止过拟合情形的出现，但是如果我们的模型已经出现了欠拟合的情形，就可以通过减少正则化参数来消除欠拟合。<h3 id="3-2-过拟合"><a href="#3-2-过拟合" class="headerlink" title="3.2 过拟合"></a>3.2 过拟合</h3>图a所示的仍然是之前已获得的房屋的大小和价格的关系数据，图b所示的是一个过拟合的模型，可以看到这个模型过度捕获了原数据的特征。不仅同之前的欠拟合模型存在同样的问题，而且过<br>拟合模型受原数据中的噪声数据影响非常严重。如图c所示，如果噪声数据严重偏离既定的数据轨道，则拟合出来的模型会发生很大改变，这个影响是灾难性的。<br><img alt="image" data-src="https://i.loli.net/2019/12/06/6gEiQUk4Orf5yz3.png" class="lazyload"><br>若模型中存在过拟合现象，应用下述方法进行解决：</li><li>增大训练的数据量：在大多数情况下发生过拟合是因为我们用于模型训练的数据量太小，搭建的模型过度捕获了数据的有限特征，这时就会出现过拟合，在增加参与模型训练的数据量后，模型自然就能捕获数据的更多特征，模型就不会过于依赖数据的个别特征。</li><li>采用正则化方法：正则化一般指在目标函数之后加上范数，用来防止模型过拟合的发生，在实践中最常用到的正则化方法有L0正则、L1正则和L2正则（正则化：自动削弱不重要的特征变量，自动从众多特征变量中提取重要的特征变量）。</li><li>Dropout方法：Dropout方法在神经网络模型中使用的频率较高，简单来说就是在神经网络模型进行前向传播的过程中，随机选取和丢弃指定层次之间的部分神经连接，因为整个过程是随机的，所以能有效防止过拟合的发生。</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>机器学习简介</title>
      <link href="/2019/12/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/"/>
      <url>/2019/12/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="机器学习简介"><a href="#机器学习简介" class="headerlink" title="机器学习简介"></a>机器学习简介</h1><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>在机器学习的历史上，一共出现了两种定义：</p><p>1956 年，开发了西洋跳棋 AI 程序的 Arthur Samuel 在标志着人工智能学科诞生的达特茅斯会议上定义了 “机器学习” 这个词，定义为，“在没有明确设置的情况下，使计算机具有学习能力的研究领域”。</p><p>1997 年，Tom Mitchell 提供了一个更现代的定义：“如果用 P 来测量程序在任务 T 中性能。若一个程序通过利用经验 E 在 T 任务中获得了性能改善，则就可以说关于任务 T 和 性能测量 P ，该程序对经验 E 进行了学习。”<br>例如：玩跳棋<br>E = 玩很多盘跳棋游戏的经验；<br>T = 玩跳棋的任务；<br>P = 程序将赢得下一场比赛的概率。</p><p>那么什么是深度学习？</p><p>深度学习是一种特殊的机器学习，用概念组成的网状层级结构来表示这个世界，每一个概念更简单的概念相连，抽象的概念通过没那么抽象的概念计算</p><p>深度学习的概念源于人工神经网络的研究，含多隐层的多层感知器就是一种深度学习结构<br>深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示</p><p>深度学习的概念由Hinton等人于2006年提出，基于深信度网(DBN)提出非监督贪心逐层训练算法，为解决深层结构相关的优化难题带来希望，随后提出多层自动编码器深层结构<br>此外，Lecun等人提出的卷积神经网络是第一个真正多层结构学习算法，它利用空间相对关系减少参数数目以提高训练性能</p><p>深度学习如今的全部价值皆通过监督式学习或经过标记的数据及算法实现</p><p>深度学习改变了传统互联网业务，例如网络搜索和广告<br>但是同时也使得许多新产品和企业以很多方式帮助人们<br>做的非常好的一个方面就是读取X光图像和人脸识别，生活中的个性化教育，精准化农业，甚至驾驶汽车以及其它一些方面</p><h2 id="2-神经网络"><a href="#2-神经网络" class="headerlink" title="2. 神经网络"></a>2. 神经网络</h2><p>从一个房价预测的例子开始说起<br>假设有一个数据集，包含了六栋房子的信息<br>知道房屋的面积是多少平方英尺或者平方米，并且知道房屋价格<br>想要拟合一个根据房屋面积预测房价的函数，于是利用线性回归可能会得到这样一条直线<br><img alt="在这里插入图片描述" data-src="https://img-blog.csdnimg.cn/20191127163206970.png" class="lazyload"><br>发现价格永远不会是负数，因此把直线弯曲一点，让它最终在零结束<br>有部分是零，而直线的部分拟合的很好</p><p>把房屋的面积作为神经网络的输入（x），通过一个单独的神经元\节点（小圆圈），最终输出了价格（y）<br>如果这是一个单神经元网络，不管规模大小，它正是通过把这些单个神经元叠加在一起来形成<br>如果把这些神经元想象成单独的乐高积木，通过搭积木来就可以完成一个更大的神经网络<br>比如：一些有关房屋的其它特征共同来预测价格，比如卧室的数量，邮政编码（交通便利程度），富裕程度等</p><p>实现之后，要做的只是输入特征x，就能得到输出y</p><p>神经网络需要给予了足够多的训练样本有关的x和y的数据<br>神经网络非常擅长计算从x到y的精准映射函数</p><h2 id="3-兴起"><a href="#3-兴起" class="headerlink" title="3. 兴起"></a>3. 兴起</h2><p>推动深度学习变得如此热门的主要因素：数据规模、计算量和算法的创新<br>事实上如今最可靠的方法来在神经网络上获得更好的性能<br>往往就是要么训练一个更大的神经网络，要么投入更多的数据，这只能在一定程度上起作用</p><p>利用传统机器学习算法训练神经网络， 性能就会变成下图红色曲线那样<br>训练一个小型的神经网络，那么这个性能可能会像下图黄色曲线表示那样<br>训练一个稍微大一点的神经网络，比如说一个中等规模的神经网络性能像下图蓝色曲线表示那样<br>训练一个非常大的神经网络，性能就会变成下图绿色曲线那样</p><p>在深度学习萌芽的初期，数据的规模以及计算量，局限在于训练一个特别大的神经网络的能力<br>无论是在CPU还是GPU上面，现在取得了巨大的进步<br>许多算法方面的创新，一直是在尝试着使得神经网络运行的更快</p><p>神经网络方面的一个巨大突破是从sigmoid函数转换到一个ReLU函数：</p><p>sigmoid 函数实现梯度下降<br>梯度接近零的时候，参数会更新的很慢<br>ReLU 函数（修正线性单元）<br>梯度对于所有输入的负值都是零，因此梯度更加不会趋向逐渐减少到零</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
